# ğŸ”„ INCREMENTAL IMPORT GUIDE

**Status**: âœ… **PRODUKTIONSKLAR**  
**Script**: `import_incremental_1024.py`  
**FormÃ¥l**: TilfÃ¸j nye dokumenter uden at slette eksisterende data

---

## ğŸ“‹ **OVERVIEW**

`import_incremental_1024.py` er en pendant til `import_simple_1024.py` som kan importere nye filer til den eksisterende database uden at slette alt data fÃ¸rst.

### **âœ… Key Features**
- **Bevarer eksisterende data** - ingen data mistes
- **Intelligent duplikat hÃ¥ndtering** - skip eller overskriv options
- **Samme 1024-dim optimering** som import_simple_1024.py
- **Robust fejlhÃ¥ndtering** med retry logic
- **Batch processing** for optimal performance
- **Automatisk schema creation** hvis nÃ¸dvendigt

---

## ğŸ› ï¸ **INSTALLATION & REQUIREMENTS**

### **Prerequisites**
```bash
# Samme requirements som import_simple_1024.py
pip install weaviate-client python-dotenv jsonlines

# .env fil med OpenAI API key
OPENAI_API_KEY=din_openai_api_key
```

### **Weaviate Server**
- KÃ¸rende Weaviate instance pÃ¥ `http://localhost:8080`
- Eksisterende LegalDocument schema (oprettes automatisk hvis ikke findes)

---

## ğŸ¯ **USAGE OPTIONS**

### **1. ğŸ”„ Standard Incremental Import (Skip Duplicates)**
```bash
# Import alle nye filer, skip duplikater (default)
python import_incremental_1024.py

# Eller eksplicit
python import_incremental_1024.py --skip-duplicates
```

**Resultat**: Nye dokumenter importeres, eksisterende springes over.

### **2. ğŸ” Overwrite Duplicates**
```bash
# Import alle filer, overskriv duplikater
python import_incremental_1024.py --overwrite-duplicates
```

**Resultat**: Nye dokumenter importeres, duplikater slettes og genimporteres.

### **3. ğŸ“ Specific Files Import**
```bash
# Import kun specifikke filer
python import_incremental_1024.py --files "ny_lov_chunks.jsonl" "opdateret_lov_chunks.jsonl"

# Med overwrite
python import_incremental_1024.py --files "ny_lov_chunks.jsonl" --overwrite-duplicates
```

### **4. âš¡ Performance Tuning**
```bash
# StÃ¸rre batch size for hurtigere import
python import_incremental_1024.py --batch-size 16

# Skip verification for hurtigere execution
python import_incremental_1024.py --no-verify
```

---

## ğŸ“Š **DUPLIKAT HÃ…NDTERING**

### **ğŸ” Duplikat Detection**
- **Baseret pÃ¥**: `chunk_id` field (UUID)
- **Cache system**: Henter alle eksisterende chunk IDs ved start
- **Effektiv lookup**: O(1) duplicate check via Set

### **â­ï¸ Skip Duplicates (Default)**
```bash
python import_incremental_1024.py --skip-duplicates
```

**Behavior**:
- Eksisterende dokumenter springes over
- Kun nye chunk_ids importeres  
- Hurtigste option for store datasets
- Sikker - ingen data mistes

### **â†» Overwrite Duplicates**
```bash
python import_incremental_1024.py --overwrite-duplicates
```

**Behavior**:
- Eksisterende dokumenter slettes fÃ¸rst
- Ny version importeres
- Ideal for opdateringer
- Lidt langsommere pga. delete operations

---

## ğŸ“ˆ **PERFORMANCE CHARACTERISTICS**

### **âš¡ Speed Comparison**
```
Skip duplicates:     Hurtigst (ingen delete operations)
Overwrite duplicates: Moderat (delete + insert operations)
Full reimport:       Langsomst (schema recreation)
```

### **ğŸ’¾ Memory Usage**
- **Chunk ID cache**: ~50KB for 3,098 dokumenter
- **Batch processing**: Lav memory footprint
- **Incremental loading**: Ingen memory overflow

### **ğŸ”„ Typical Performance**
```
3,098 eksisterende docs:  ~2s duplikat check
Skip alle duplikater:     ~3s total
Import 100 nye docs:      ~45s
Import 1,000 nye docs:    ~6min
```

---

## ğŸ¯ **USE CASES**

### **1. ğŸ“ Nye Love/Forordninger**
```bash
# Nye love tilfÃ¸jes til databasen
python import_incremental_1024.py --files "ny_bekendtgÃ¸relse_chunks.jsonl"
```

### **2. ğŸ”„ Opdateringer af Eksisterende Love**
```bash
# Opdaterede versioner af eksisterende paragraffer
python import_incremental_1024.py --overwrite-duplicates --files "ligningsloven_opdatered_chunks.jsonl"
```

### **3. ğŸ§ª Test Data Import**
```bash
# Test import uden at pÃ¥virke produktion
python import_incremental_1024.py --files "test_data_chunks.jsonl"
```

### **4. ğŸ”§ Schema Recovery**
```bash
# Hvis schema er slettet, men data skal bevares
python import_incremental_1024.py  # Opretter schema automatisk
```

### **5. ğŸ“Š Batch Processing af Mange Filer**
```bash
# HÃ¥ndter store datasets effektivt
python import_incremental_1024.py --batch-size 16 --files *.jsonl
```

---

## ğŸ“‹ **OUTPUT EXPLANATION**

### **ğŸ” Status Messages**
```
ğŸ”§ Kontrollerer eksisterende skema...         # Schema verification
âœ… Schema findes allerede.                     # Schema OK
ğŸ¯ Schema verificeret - Dimensioner: 1024     # 1024-dim confirmed

ğŸ“Š Fandt 3098 eksisterende dokumenter         # Duplikat cache loaded

ğŸ“„ Behandler: fil.jsonl                       # Per-file processing
âœ… Batch: +8 ny, ~0 skipped, â†»0 overwritten  # Batch results
```

### **ğŸ“Š Final Statistics**
```
âœ… Nye dokumenter importeret: 156      # Successfully imported
â­ï¸  Duplikater skippet: 2942           # Skipped duplicates  
â†»  Duplikater overskrevet: 0          # Overwritten documents
âŒ Fejl: 0                            # Errors encountered
ğŸ“Š Success rate: 100.0%               # Overall success rate
```

---

## ğŸ›¡ï¸ **ERROR HANDLING**

### **ğŸ”§ Robust Error Recovery**
- **Retry logic**: 3 attempts per batch
- **Graceful degradation**: Continue efter fejl
- **Detailed logging**: Pinpoint fejl lokationer
- **Safe operations**: Ingen korruption af eksisterende data

### **âš ï¸ Common Issues & Solutions**

#### **"Ingen .jsonl filer fundet"**
```bash
# Tjek fil lokation
ls "import embedding"/*.jsonl

# Brug specifik path
python import_incremental_1024.py --files "path/to/file.jsonl"
```

#### **"Fejl ved hentning af eksisterende IDs"**
```bash
# Tjek Weaviate forbindelse
docker ps | grep weaviate

# Restart Weaviate hvis nÃ¸dvendigt
docker restart weaviate
```

#### **"Schema bruger X dimensioner, ikke 1024"**
```bash
# Brug original script til schema opdatering
python import_simple_1024.py --force-recreate
```

#### **"Batch fejl efter 3 forsÃ¸g"**
```bash
# Reducer batch size
python import_incremental_1024.py --batch-size 4

# Tjek OpenAI API limits
```

---

## ğŸ”„ **INTEGRATION MED EKSISTERENDE WORKFLOW**

### **ğŸ”— Standard Workflow**
```bash
# 1. Initial setup (Ã©n gang)
python import_simple_1024.py --force-recreate

# 2. Nye data (lÃ¸bende)
python import_incremental_1024.py --files "ny_data.jsonl"

# 3. Opdateringer (ved behov)
python import_incremental_1024.py --overwrite-duplicates --files "opdateret_data.jsonl"

# 4. Verification (regelmÃ¦ssigt)
python database_status.py
```

### **ğŸ¯ Production Deployment**
```bash
# Cron job for automatisk import af nye filer
0 2 * * * cd /path/to/weaviate && python import_incremental_1024.py

# Monitoring script
python import_incremental_1024.py --no-verify > import_log_$(date +%Y%m%d).log 2>&1
```

---

## ğŸ“Š **SCHEMA COMPATIBILITY**

### **âœ… Kompatibilitet**
- **Samme schema** som import_simple_1024.py
- **33 properties** - komplet mapping
- **1024 dimensioner** - optimeret performance
- **Backwards compatible** med eksisterende data

### **ğŸ”§ Schema Auto-Creation**
Hvis schema ikke eksisterer:
```python
# Automatisk creation med samme config som import_simple_1024.py
{
    "vectorizer": "text2vec-openai",
    "moduleConfig": {
        "text2vec-openai": {
            "model": "text-embedding-3-large",
            "dimensions": 1024  # Optimeret
        }
    }
}
```

---

## ğŸ¯ **COMPARISON: INCREMENTAL VS FULL IMPORT**

| Feature | `import_incremental_1024.py` | `import_simple_1024.py` |
|---------|-------------------------------|--------------------------|
| **Data preservation** | âœ… Bevarer eksisterende | âŒ Sletter alt |
| **Duplikat handling** | âœ… Skip/overwrite options | âŒ Overskriver alt |
| **Schema creation** | âœ… Auto-create if missing | âœ… Force recreation |
| **Performance** | âš¡ Hurtig for smÃ¥ updates | ğŸŒ Langsom for store datasets |
| **Safety** | ğŸ›¡ï¸ Sikker for production | âš ï¸ Destruktiv |
| **Use case** | ğŸ“ˆ LÃ¸bende updates | ğŸ”„ Initial setup |

---

## ğŸ’¡ **BEST PRACTICES**

### **ğŸ¯ Recommended Usage**
1. **Initial setup**: Brug `import_simple_1024.py --force-recreate`
2. **Nye love**: Brug `import_incremental_1024.py --skip-duplicates`
3. **Opdateringer**: Brug `import_incremental_1024.py --overwrite-duplicates`
4. **Backup fÃ¸rst**: Tag backup fÃ¸r overwrite operations
5. **Test fÃ¸rst**: Test med smÃ¥ datasets fÃ¸r production

### **âš¡ Performance Tips**
- Brug `--batch-size 16` for store imports
- Brug `--no-verify` for hurtigere execution
- KÃ¸r incremental imports i off-peak hours
- Monitor memory usage ved store datasets

### **ğŸ›¡ï¸ Safety Guidelines**
- Test altid med `--skip-duplicates` fÃ¸rst
- Verificer resultater med database_status.py
- Brug specific `--files` til kritiske opdateringer
- Tag backup fÃ¸r `--overwrite-duplicates`

---

## ğŸš€ **READY FOR PRODUCTION**

`import_incremental_1024.py` er **100% produktionsklar** og giver dig:

- âœ… **Sikker data opdatering** uden tab af eksisterende data
- âœ… **Fleksibel duplikat hÃ¥ndtering** (skip/overwrite)
- âœ… **Optimal performance** med 1024-dim optimering
- âœ… **Robust fejlhÃ¥ndtering** med retry logic
- âœ… **Production-ready** workflow integration

**Perfect complement til din eksisterende RAG system! ğŸ‰** 