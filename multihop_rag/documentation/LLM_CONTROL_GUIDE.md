# ğŸ¤– LLM CONTROL GUIDE - Hvor og Hvordan Output PÃ¥virkes

**Komplet oversigt over alle steder hvor LLM er involveret og output kan kontrolleres**

## ğŸ¯ **OVERVIEW: LLM INVOLVERING I MULTIHOP RAG**

LangChain Multihop RAG systemet har **4 primÃ¦re LLM interaction punkter** plus flere indstillinger der pÃ¥virker output:

```
ğŸ”„ MULTIHOP PIPELINE
â”œâ”€â”€ ğŸ§  LLM PUNKT 1: Query Analysis
â”œâ”€â”€ ğŸ” RETRIEVAL: Search Engine (konfigurerbar vÃ¦gtning)
â”œâ”€â”€ ğŸ§  LLM PUNKT 2: Document Analysis (HOP 1)
â”œâ”€â”€ ğŸ” RETRIEVAL: Follow-up Search (baseret pÃ¥ LLM output)
â”œâ”€â”€ ğŸ§  LLM PUNKT 3: Document Analysis (HOP 2)
â”œâ”€â”€ ğŸ” RETRIEVAL: Deep Search (baseret pÃ¥ LLM output)
â””â”€â”€ ğŸ§  LLM PUNKT 4: Final Answer Generation
```

---

## ğŸ§  **LLM PUNKT 1: QUERY ANALYSIS**

### **Fil:** `juridisk_rag_langchain.py` (linje 125-142)
### **FormÃ¥l:** Analyser spÃ¸rgsmÃ¥l og planlÃ¦g multihop strategi

```python
self.query_analysis_template = PromptTemplate.from_template("""
Du er en ekspert i dansk skatteret og query-analyse.

Analyser fÃ¸lgende juridiske spÃ¸rgsmÃ¥l og identificÃ©r:
1. Hvilke love der er relevante
2. Hvilke paragraffer der nÃ¦vnes
3. Hvilke juridiske koncepter der skal undersÃ¸ges
4. Om spÃ¸rgsmÃ¥let krÃ¦ver multihop reasoning (flere sÃ¸gninger)

SPÃ˜RGSMÃ…L: {question}

SVAR I JSON FORMAT:
{{
    "laws": ["lov1", "lov2"],
    "paragraphs": ["Â§ X", "Â§ Y"],
    "concepts": ["koncept1", "koncept2"],
    "needs_multihop": true/false,
    "reasoning": "forklaring af hvorfor multihop er nÃ¸dvendig",
    "search_queries": ["query1", "query2", "query3"]
}}
""")
```

### **ğŸ›ï¸ HVOR KAN DU PÃ…VIRKE OUTPUT:**

1. **Prompt Engineering:**
   - âœï¸ **Rediger template** (linje 125-142)
   - ğŸ“ **TilfÃ¸j flere instruktioner** til JSON format
   - ğŸ¯ **Specificer juridiske domÃ¦ner** mere prÃ¦cist
   - ğŸ” **Ã†ndre query generation logik**

2. **Model Indstillinger:**
   ```python
   # I LangChainRAGConfig
   temperature: float = 0.1        # PÃ…VIRKER: Kreativitet i query analyse
   max_tokens: int = 2000         # PÃ…VIRKER: Hvor detaljeret analyse
   model: str = "gpt-4o-2024-08-06"  # PÃ…VIRKER: Intelligens niveau
   ```

---

## ğŸ§  **LLM PUNKT 2: DOCUMENT ANALYSIS** 

### **Fil:** `juridisk_rag_langchain.py` (linje 144-164)
### **FormÃ¥l:** Analyser fundne dokumenter og beslut nÃ¦ste sÃ¸gning

```python
self.doc_analysis_template = PromptTemplate.from_template("""
Du er ekspert i juridisk dokumentanalyse.

Analyser fÃ¸lgende dokumenter og identificÃ©r:
1. NÃ¸gleinformation der besvarer spÃ¸rgsmÃ¥let
2. Manglende information der krÃ¦ver yderligere sÃ¸gning
3. Referencer til andre paragraffer/love
4. Juridiske koncepter der skal uddybes

SPÃ˜RGSMÃ…L: {question}

DOKUMENTER:
{documents}

SVAR I JSON FORMAT:
{{
    "key_findings": ["finding1", "finding2"],
    "missing_info": ["info1", "info2"],
    "references": ["ref1", "ref2"],
    "needs_more_search": true/false,
    "next_queries": ["query1", "query2"]
}}
""")
```

### **ğŸ›ï¸ HVOR KAN DU PÃ…VIRKE OUTPUT:**

1. **Prompt Engineering:**
   - âœï¸ **Rediger document analysis prompt** (linje 144-164)
   - ğŸ” **Ã†ndre kriterier** for "needs_more_search"
   - ğŸ“Š **Specificer hvilke referencer** der skal prioriteres
   - ğŸ¯ **TilfÃ¸j juridisk domÃ¦ne-specifik analyse**

2. **Document Formatting:**
   ```python
   # I _format_documents_for_prompt() (linje 481-503)
   formatted.append(f"""
   DOKUMENT {i}:
   Reference: {reference}                    # PÃ…VIRKER: Hvordan LLM ser dokumenter
   Chunk ID: {metadata.get('chunk_id')[:8]}  # PÃ…VIRKER: Context for LLM
   Type: {metadata.get('type')}              # PÃ…VIRKER: Prioritering logik
   
   INDHOLD:
   {doc.page_content[:1000]}                 # PÃ…VIRKER: Hvor meget tekst LLM ser
   """)
   ```

---

## ğŸ§  **LLM PUNKT 3: FINAL ANSWER GENERATION**

### **Fil:** `juridisk_rag_langchain.py` (linje 166-195)
### **FormÃ¥l:** Generer komplet svar baseret pÃ¥ alle dokumenter

```python
self.answer_template = PromptTemplate.from_template("""
Du er en hÃ¸jt specialiseret ekspert i dansk skatteret.

Baseret pÃ¥ dokumenterne fra flere sÃ¸gninger, giv et komplet svar pÃ¥ spÃ¸rgsmÃ¥let.

VIGTIGE INSTRUKSER:
- Svar UDELUKKENDE baseret pÃ¥ de vedlagte dokumenter
- Citer prÃ¦cise kilder (paragraf, stykke, nummer, lov)
- Forklar juridiske sammenhÃ¦nge og referencer mellem dokumenter
- Strukturer svaret logisk
- Angiv hvis information mangler

SPÃ˜RGSMÃ…L: {question}

HOP 1 DOKUMENTER:
{hop1_docs}

HOP 2 DOKUMENTER:
{hop2_docs}

HOP 3 DOKUMENTER:
{hop3_docs}

REASONING PATH:
{reasoning_path}

KOMPLET JURIDISK SVAR:
""")
```

### **ğŸ›ï¸ HVOR KAN DU PÃ…VIRKE OUTPUT:**

1. **Prompt Engineering:**
   - âœï¸ **Rediger instrukser** (linje 173-179)
   - ğŸ“ **TilfÃ¸j formatering requirements**
   - ğŸ¯ **Specificer citationsformat**
   - ğŸ“Š **Ã†ndre strukturering instruktioner**

2. **Context Preparation:**
   ```python
   # I _generate_multihop_answer() (linje 420-442)
   hop1_text = self._format_documents_for_prompt(all_documents["hop1"])
   hop2_text = self._format_documents_for_prompt(all_documents["hop2"])
   hop3_text = self._format_documents_for_prompt(all_documents["hop3"])
   
   # PÃ…VIRKER: Hvilke dokumenter LLM ser
   # PÃ…VIRKER: RÃ¦kkefÃ¸lge af information
   # PÃ…VIRKER: Context balance mellem hops
   ```

---

## ğŸ§  **LLM PUNKT 4: SINGLE-HOP FALLBACK**

### **Fil:** `juridisk_rag_langchain.py` (linje 504-533)
### **FormÃ¥l:** Simpel generation nÃ¥r multihop ikke bruges

```python
simple_prompt = f"""
Du er ekspert i dansk skatteret. Besvar fÃ¸lgende spÃ¸rgsmÃ¥l baseret pÃ¥ dokumenterne.

SPÃ˜RGSMÃ…L: {question}

DOKUMENTER:
{docs_text}

SVAR:
"""
```

### **ğŸ›ï¸ HVOR KAN DU PÃ…VIRKE OUTPUT:**
- âœï¸ **Rediger simple prompt** direkte i koden
- ğŸ“ **TilfÃ¸j instruktioner** for enkle svar

---

## âš™ï¸ **KONFIGURATION INDSTILLINGER DER PÃ…VIRKER OUTPUT**

### **1. LLM CORE SETTINGS**

```python
# I LangChainRAGConfig (langchain_rag_config.py)
class LangChainRAGConfig:
    # === DIREKTE LLM PÃ…VIRKNING ===
    model: str = "gpt-4o-2024-08-06"     # ğŸ¯ Model intelligens
    temperature: float = 0.1             # ğŸ² Kreativitet/randomness
    max_tokens: int = 2000               # ğŸ“ Svar lÃ¦ngde
```

**ğŸ›ï¸ PÃ…VIRKNING:**
- **Temperature 0.0-0.2:** Meget prÃ¦cise, konsistente svar
- **Temperature 0.2-0.5:** Balanceret kreativitet og prÃ¦cision  
- **Temperature 0.5-1.0:** Kreative, varierede svar
- **Max Tokens:** BegrÃ¦nser hvor detaljerede svar kan vÃ¦re

### **2. MULTIHOP REASONING SETTINGS**

```python
# === MULTIHOP PÃ…VIRKNING ===
max_documents_per_hop: int = 5           # ğŸ“„ Information density per hop
max_hops: int = 3                        # ğŸ”„ Hvor dybt systemet tÃ¦nker
hop_confidence_threshold: float = 0.4    # ğŸ¯ Hvor sikker fÃ¸r nÃ¦ste hop
max_reasoning_depth: int = 3             # ğŸ§  Reasoning kompleksitet
enable_multihop: bool = True             # ğŸ”€ On/off switch
```

**ğŸ›ï¸ PÃ…VIRKNING:**
- **Flere docs per hop:** Mere information, men potentiel noise
- **Flere hops:** Dybere analyse, men langsommere
- **Lavere confidence threshold:** Flere follow-up sÃ¸gninger
- **HÃ¸jere reasoning depth:** Mere kompleks LLM reasoning

### **3. CONTEXT SETTINGS**

```python
# === CONTEXT PÃ…VIRKNING ===
max_context_length: int = 12000          # ğŸ“Š Total information til LLM
context_overlap: int = 300               # ğŸ”— Overlap mellem chunks
include_related_notes: bool = True       # ğŸ“ Inkluder noter/kommentarer
```

**ğŸ›ï¸ PÃ…VIRKNING:**
- **StÃ¸rre context:** LLM ser mere, men kan blive distrahet
- **Context overlap:** Bedre sammenhÃ¦ng, men redundans
- **Related notes:** Mere baggrund, men potentiel irrelevans

---

## ğŸ” **RETRIEVAL SETTINGS DER PÃ…VIRKER LLM INPUT**

### **1. SEARCH STRATEGY**

```python
# I SearchStrategy enum
class SearchStrategy(Enum):
    AUTO = "auto"                    # ğŸ¤– Intelligent auto-valg
    PARAGRAPH_FIRST = "paragraph_first"  # âš–ï¸ Juridiske docs fÃ¸rst
    SEMANTIC_FIRST = "semantic_first"    # ğŸ§  Konceptuel sÃ¸gning fÃ¸rst
    HYBRID = "hybrid"                    # ğŸ”€ Balanceret mix
    MULTIHOP = "multihop"               # ğŸ¯ Optimeret til multihop
```

**ğŸ›ï¸ PÃ…VIRKNING PÃ… LLM:**
- **PARAGRAPH_FIRST:** LLM fÃ¥r prÃ¦cise juridiske docs â†’ mere akkurate svar
- **SEMANTIC_FIRST:** LLM fÃ¥r konceptuelle docs â†’ mere forklarende svar
- **HYBRID:** LLM fÃ¥r blandet indhold â†’ balancerede svar

### **2. SEARCH ENGINE VÃ†GTNING**

```python
# I search_engine.py - _search_hybrid() (linje 155-185)
per_method = max(1, limit // 3)

# Prioritering i hybrid sÃ¸gning:
# 1. HÃ¸jeste prioritet: paragraf resultater
all_results.extend([(r, 'paragraph') for r in paragraph_results])

# 2. Mellem prioritet: semantisk resultater  
all_results.extend([(r, 'semantic') for r in semantic_results])

# 3. Laveste prioritet: keyword resultater
all_results.extend([(r, 'keyword') for r in keyword_results])
```

**ğŸ›ï¸ HVOR KAN DU Ã†NDRE VÃ†GTNING:**
```python
# Rediger prioritering i _search_hybrid()
per_method = max(1, limit // 2)  # ğŸ¯ Giv mere plads til top metoder

# Ã†ndre vÃ¦gtning ratio:
paragraph_weight = 0.5  # 50% til paragraffer
semantic_weight = 0.3   # 30% til semantisk  
keyword_weight = 0.2    # 20% til keyword
```

### **3. JURIDISK BOOST**

```python
# I search_engine.py - _search_semantic_with_juridisk_boost() (linje 252-285)
# FÃ¸rst: SÃ¸g kun i paragraffer
.with_where({
    "path": ["type"],
    "operator": "Equal", 
    "valueText": "paragraf"     # ğŸ¯ BOOST til juridiske docs
})
.with_limit(limit // 2)         # ğŸ“Š 50% af resultater fra paragraffer
```

**ğŸ›ï¸ HVOR KAN DU Ã†NDRE BOOST:**
```python
# Ã†ndre boost ratio
paragraph_limit = limit * 0.7   # ğŸ¯ 70% fra paragraffer i stedet for 50%

# TilfÃ¸j andre juridiske boost kriterier
boost_types = ["paragraf", "stykke", "nummer"]  # ğŸ“Š Flere juridiske typer
```

---

## ğŸ“Š **CONFIDENCE SCORING DER PÃ…VIRKER OUTPUT**

### **Fil:** `juridisk_rag_langchain.py` (linje 568-593)

```python
def _calculate_multihop_confidence(self, all_documents: Dict, reasoning_path: List) -> float:
    base_score = 0.5
    
    # Boost for flere dokumenter
    total_docs = sum(len(docs) for docs in all_documents.values())
    if total_docs >= 5:
        base_score += 0.2           # ğŸ“Š +20% for mange docs
    elif total_docs >= 3:
        base_score += 0.1           # ğŸ“Š +10% for medium docs
    
    # Boost for successful multihop
    successful_hops = len([step for step in reasoning_path if "hop" in step["step"]])
    base_score += successful_hops * 0.1  # ğŸ“Š +10% per hop
    
    # Boost for paragraph documents
    paragraph_docs = sum(1 for docs in all_documents.values() for doc in docs 
                        if doc.metadata.get('type') == 'paragraf')
    if paragraph_docs > 0:
        base_score += 0.1           # ğŸ“Š +10% for juridiske docs
    
    return min(base_score, 1.0)
```

**ğŸ›ï¸ HVOR KAN DU Ã†NDRE CONFIDENCE VÃ†GTNING:**
```python
# Ã†ndre boost vÃ¦rdier:
document_boost = 0.3        # Ã˜g boost for mange docs
hop_boost = 0.15           # Ã˜g boost per hop
paragraph_boost = 0.2      # Ã˜g boost for juridiske docs

# TilfÃ¸j nye boost kriterier:
if any("kildeskatteloven" in doc.metadata.get('title', '') for docs in all_documents.values() for doc in docs):
    base_score += 0.15     # ğŸ“Š Extra boost for KSL docs
```

---

## ğŸ¯ **DOCUMENT FILTERING & PRIORITERING**

### **1. WHERE FILTERS (PÃ¥virker hvad LLM ser)**

```python
# I search_engine.py - _build_juridisk_where_filter() (linje 287-322)
def _build_juridisk_where_filter(self, query: str) -> Optional[Dict]:
    # Match Â§ nummer
    if section_match:
        return {
            "path": ["paragraph"],
            "operator": "Like",
            "valueText": f"*Â§ {section_num}*"  # ğŸ¯ Kun Â§ docs til LLM
        }
    
    # Match lovnavne
    if 'kildeskatteloven' in query.lower():
        return {
            "path": ["title"],
            "operator": "Like", 
            "valueText": "*kildeskattelov*"    # ğŸ¯ Kun KSL docs til LLM
        }
```

**ğŸ›ï¸ HVOR KAN DU Ã†NDRE FILTERING:**
```python
# TilfÃ¸j flere juridiske mÃ¸nstre:
juridisk_patterns = [
    'Â§', 'paragraf', 'stk', 'stykke', 'nr', 'nummer', 
    'kildeskatteloven', 'ligningsloven', 'aktieavancebeskatningsloven',
    'ksl', 'lov nr', 'bekendtgÃ¸relse',
    'cirkulÃ¦re', 'vejledning', 'kommentar'  # ğŸ“Š Nye mÃ¸nstre
]

# Ã†ndre prioritering af lovnavne:
if 'aktieavancebeskatningsloven' in query.lower():
    priority_boost = 0.3  # ğŸ¯ HÃ¸jere prioritet til ABL
```

### **2. DOCUMENT TYPE PRIORITERING**

```python
# I search_engine.py - _format_search_results() (linje 346-385)
# Chunk vÃ¦gtning baseret pÃ¥ type
if chunk.get('type') == 'paragraf':
    result['priority_boost'] = 1.5      # ğŸ“Š 50% boost til paragraffer
elif chunk.get('type') == 'stykke':
    result['priority_boost'] = 1.3      # ğŸ“Š 30% boost til stykker
elif chunk.get('type') == 'nummer':
    result['priority_boost'] = 1.2      # ğŸ“Š 20% boost til numre
else:
    result['priority_boost'] = 1.0      # ğŸ“Š Standard vÃ¦gt
```

---

## ğŸ”§ **PRAKTISKE CUSTOMIZATION EKSEMPLER**

### **1. Ã†ndreTemperature for Forskellige Opgaver**

```python
# Meget prÃ¦cise juridiske opslag
precise_config = LangChainRAGConfig(temperature=0.01)

# Kreative juridiske analyser  
creative_config = LangChainRAGConfig(temperature=0.3)

# Balanceret juridisk rÃ¥dgivning
balanced_config = LangChainRAGConfig(temperature=0.15)
```

### **2. Custom Prompt for Specifik Juridisk Analyse**

```python
# I juridisk_rag_langchain.py - tilfÃ¸j specialiseret template
self.tax_comparison_template = PromptTemplate.from_template("""
Du er ekspert i sammenligning af skattelovgivning.

Analyser UDELUKKENDE forskelle og ligheder mellem:
- Specifikke paragraffer
- Juridiske begreber  
- Praktisk anvendelse
- Historisk udvikling

SAMMENLIGN: {question}

DOKUMENTER:
{documents}

FORMAT SVAR SOM:
LIGHEDER: [...]
FORSKELLE: [...]
PRAKTISK BETYDNING: [...]
""")
```

### **3. Ã†ndre Document VÃ¦gtning for Specialiserede Emner**

```python
# Boost til specifikke love
def custom_law_boost(self, result: Dict) -> float:
    title = result.get('title', '').lower()
    boost = 1.0
    
    if 'kildeskatteloven' in title:
        boost *= 1.8    # ğŸ¯ 80% boost til KSL
    elif 'ligningsloven' in title:
        boost *= 1.5    # ğŸ¯ 50% boost til LL
    elif 'aktieavancebeskatningsloven' in title:
        boost *= 1.3    # ğŸ¯ 30% boost til ABL
    
    return boost
```

### **4. Custom Confidence Beregning**

```python
def custom_confidence_calculation(self, all_documents: Dict, query: str) -> float:
    base_score = 0.3
    
    # Juridisk specifik confidence
    if any('Â§' in query for query in [query]):
        base_score += 0.3  # ğŸ¯ Paragraf spÃ¸rgsmÃ¥l er mere sikre
    
    # Lovnavn boost
    law_mentions = sum(1 for doc in all_documents.values() 
                      if any(law in doc.metadata.get('title', '') 
                            for law in ['kildeskatteloven', 'ligningsloven']))
    base_score += law_mentions * 0.1
    
    return min(base_score, 1.0)
```

---

## ğŸ“‹ **FULD CHECKLIST: ALLE OUTPUT KONTROL PUNKTER**

### **ğŸ§  LLM Prompt Templates (4 steder)**
- [ ] Query Analysis Template (linje 125-142)
- [ ] Document Analysis Template (linje 144-164)  
- [ ] Final Answer Template (linje 166-195)
- [ ] Single-hop Prompt (linje 504-533)

### **âš™ï¸ LLM Model Settings (3 steder)**
- [ ] Temperature (kreativitet)
- [ ] Max Tokens (svar lÃ¦ngde)
- [ ] Model choice (intelligens niveau)

### **ğŸ”„ Multihop Logic (5 steder)**
- [ ] Max hops (dybde)
- [ ] Docs per hop (information density)
- [ ] Confidence threshold (fÃ¸lsomhed)
- [ ] Reasoning depth (kompleksitet)
- [ ] Enable/disable multihop

### **ğŸ“Š Context Preparation (3 steder)**
- [ ] Max context length
- [ ] Context overlap
- [ ] Document formatting for LLM

### **ğŸ” Search & Retrieval (6 steder)**
- [ ] Search strategy choice
- [ ] Hybrid vÃ¦gtning
- [ ] Juridisk boost ratio
- [ ] Where filters
- [ ] Document type prioritering  
- [ ] Confidence scoring

### **ğŸ¯ Document Selection (4 steder)**
- [ ] Search limit per hop
- [ ] Document type filtering
- [ ] Law name prioritering
- [ ] Chunk vÃ¦gtning

---

## ğŸš€ **KONKLUSION**

Du har nu **komplet kontrol** over alle aspekter af LLM output i Multihop RAG systemet:

- **4 LLM interaction punkter** med custom prompts
- **12+ konfiguration parametre** der pÃ¥virker LLM behavior  
- **6 retrieval settings** der styrer hvad LLM ser
- **8 document vÃ¦gtning mekanismer** der prioriterer information
- **Custom confidence scoring** til at vurdere svar kvalitet

**ğŸ¯ Ved at justere disse parametre kan du fine-tune systemet til specifikke juridiske domÃ¦ner, opgavetyper, og kvalitets krav!** 